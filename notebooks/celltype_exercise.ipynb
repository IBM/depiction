{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of a super simple model for celltype classification and explanation of its predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "!which python\n",
    "!python --version\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "!pwd #  start jupyter under notebooks/ for correct relative paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a look at the data\n",
    "labels are categories 1-20, here's the associated celltype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_series = pd.read_csv('../data/single-cell/metadata.csv', index_col=0, dtype=str).rename_axis(None)\n",
    "meta_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 unbalanced classes, and over 80k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/single-cell/data.csv')\n",
    "sns.countplot(data_df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class wise probabilities\n",
    "def one_hot_encoding(classes):\n",
    "    return to_categorical(classes)[:, 1:]  # remove category 0\n",
    "\n",
    "def one_hot_decoding(labels):\n",
    "    return labels.argmax(axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data_df['category'].values\n",
    "labels = one_hot_encoding(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_decoding(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels # model output (softmax) for classification shows probabilities per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data from 0 to 1\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "data = min_max_scaler.fit_transform(data_df.drop('category', axis=1).values)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = train_test_split(\n",
    "    data, labels,\n",
    "    # TODO make choices on keyword arguments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data_train, labels_train))\n",
    "dataset = dataset.shuffle(2 * batchsize).batch(batchsize)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((data_test, labels_test))\n",
    "testset = testset.batch(batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a simple model\n",
    "start with a dense/linear layer, train a few epochs and grow/adapt your network architecture as you like\n",
    "for classification end with a softmax for output probability per celltype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    # TODO provide layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluation on testset on every epoch\n",
    "# log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(\n",
    "    dataset,\n",
    "    epochs=20, steps_per_epoch=np.ceil(data_train.shape[0]/batchsize),\n",
    "    validation_data=testset, #  callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now what did the model learn?\n",
    "Let's save to model to use an explainer from `depiction` to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entire model to a HDF5 file\n",
    "model.save('./celltype_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To recreate the exact same model, including weights and optimizer.\n",
    "# model = tf.keras.models.load_model('./celltype_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Explaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are going to apply _lime_ and _anchor_ to the model to explain the prediction for given samples\n",
    "keep in mind those methods are trained on data themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use DataFrame to track feature names and choose samples of given class\n",
    "test_df = pd.DataFrame(\n",
    "    np.append(data_test, one_hot_decoding(labels_test)[:, None], axis=1), columns=data_df.columns\n",
    ")\n",
    "# valid_df, test_df = train_test_split(test_df, test_size=0.67, stratify=test_df.category)\n",
    "data_valid, data_test, labels_valid, labels_test = train_test_split(\n",
    "    data_test, labels_test, test_size=0.67, stratify=test_df.category\n",
    ")\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the pretrained model  with `depiction`\n",
    "by implementing a class inheriting from `depiction.models.Model`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the saved model\n",
    "!pwd\n",
    "!ls\n",
    "!ls ~/.keras/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import depiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from depiction.models.base.base_model import BaseModel\n",
    "from depiction.core import Task, DataType\n",
    "\n",
    "class CellTyper(BaseModel):\n",
    "    \"\"\"Classifier of single cells to be explained.\"\"\"\n",
    "\n",
    "    def __init__(self, filename, directory): \n",
    "        \"\"\"Initialize the Model.\"\"\"\n",
    "        super(CellTyper, self).__init__(Task.CLASSIFICATION, DataType.TABULAR)\n",
    "        self.model_path = os.path.join(os.path.expanduser(directory), filename)\n",
    "        self.model = None # TODO load your model from disk\n",
    "\n",
    "    def predict(self, sample, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Run the model for inference on a given sample and with the provided\n",
    "        parameters.\n",
    "\n",
    "        Args:\n",
    "            sample (object): an input sample for the model.\n",
    "            args (list): list of arguments.\n",
    "            kwargs (dict): list of key-value arguments.\n",
    "\n",
    "        Returns:\n",
    "            a prediction for the model on the given sample.\n",
    "        \"\"\"\n",
    "        return self.model.predict(\n",
    "            sample) # TODO return prediction of sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We actually just need the results from prediction, not access to the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained classifier, or use a pretrained one with directory '~/.keras/models'\n",
    "classifier = CellTyper(filename='celltype_model.h5', directory='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer weights\n",
    "are only somewhat interpretable if the model has a single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_model = tf.keras.models.load_model(os.path.expanduser('~/.keras/models/celltype_model.h5'))\n",
    "weights = None  # TODO access weights from single_layer_model\n",
    "sns.heatmap(pd.DataFrame(\n",
    "    weights,\n",
    "    index=data_df.columns[:-1],\n",
    "    columns=meta_series.values\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability methods\n",
    "helper functions and a widget to sample from a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.interpreters.u_wash.u_washer import UWasher\n",
    "from depiction.core import DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = meta_series.to_dict()['cell type name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_configs = {\n",
    "        'top_labels': 1\n",
    "    }\n",
    "interpreter_params = {\n",
    "        # TODO provide interpreter params\n",
    "}\n",
    "\n",
    "explainer = UWasher(\"lime\", classifier, **interpreter_params)\n",
    "\n",
    "id_sample_to_explain = 0\n",
    "# explain the chosen instance wrt the chosen labels\n",
    "explainer.interpret(test_df.values[id_sample_to_explain, :-1], explanation_configs=explanation_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Widgets to look at random sample from class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_from_class(label):\n",
    "    id_sample_to_explain = test_df.reset_index().query('category==@label').sample(n=1).index[0]\n",
    "    print('Interpreting sample with index {} in test_df'.format(id_sample_to_explain))\n",
    "    return id_sample_to_explain\n",
    "\n",
    "\n",
    "def interpret_with_lime(id_sample_to_explain):\n",
    "# Create a LIME tabular interpreter\n",
    "    explanation_configs = {\n",
    "        'top_labels': 1\n",
    "    }\n",
    "    interpreter_params = {\n",
    "        # TODO provide interpreter params\n",
    "    }\n",
    "\n",
    "    explainer = UWasher(\"lime\", classifier, **interpreter_params)\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    explainer.interpret(test_df.values[id_sample_to_explain, :-1], explanation_configs=explanation_configs)\n",
    "\n",
    "\n",
    "def interpret_with_anchor(id_sample_to_explain):\n",
    "    explanation_configs = {}\n",
    "    interpreter_params = {\n",
    "        'feature_names': data_df.columns[:-1],\n",
    "        'class_names': class_names.values(),\n",
    "        'categorical_names': {}\n",
    "    }\n",
    "\n",
    "    explainer = UWasher('anchors', classifier, **interpreter_params)  \n",
    "    \n",
    "    explainer.explainer.fit(\n",
    "        data_train, labels_train, data_valid, labels_valid #.astype(np.int)\n",
    "    )\n",
    "\n",
    "\n",
    "    # explain the chosen instance wrt the chosen labels\n",
    "    def new_predict(sample, **kwargs):\n",
    "        return np.argmax(classifier.predict(sample,**kwargs), axis=1)\n",
    "    explainer.interpret(test_df.values[id_sample_to_explain, :-1], explanation_configs=explanation_configs,callback=new_predict)\n",
    "\n",
    "    \n",
    "def interpret_random_from_class(label, interpreter):\n",
    "    id_sample_to_explain = random_from_class(label)\n",
    "    if interpreter == 'lime':\n",
    "        interpret_with_lime(id_sample_to_explain)\n",
    "    elif interpreter == 'anchor':\n",
    "        interpret_with_anchor(id_sample_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(interpret_random_from_class, label=[(v, k) for k, v in class_names.items()],\n",
    "         interpreter=['lime', 'anchor']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_with_anchor(8373)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare qualitatively to __B__ and **C** (thought the image is not depicting this exact dataset)\n",
    "![manual_gated](https://science.sciencemag.org/content/sci/332/6030/687/F2.large.jpg?width=800&height=600&carousel=1)\n",
    "from https://science.sciencemag.org/content/332/6030/687/tab-figures-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}