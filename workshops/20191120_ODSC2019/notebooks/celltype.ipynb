{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "import tensorflow as tf; tf.logging.set_verbosity(tf.logging.ERROR)  # suppress deprecation messages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from depiction.models.base.base_model import BaseModel\n",
    "from depiction.models.examples.celltype.celltype import CellTyper\n",
    "from depiction.interpreters.u_wash.u_washer import UWasher\n",
    "from depiction.interpreters.alibi import Counterfactual\n",
    "from depiction.interpreters.aix360.rule_based_model import RuleAIX360\n",
    "from depiction.models.base import BinarizedClassifier\n",
    "from depiction.core import Task, DataType\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "datapath = '../data/single-cell/data.csv'\n",
    "data_df = pd.read_csv(datapath)\n",
    "\n",
    "#scale the data from 0 to 1\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "data = min_max_scaler.fit_transform(data_df.drop('category', axis=1).values)\n",
    "data_df = pd.DataFrame(\n",
    "    np.append(data, data_df['category'].values[:, None], axis=1), index=data_df.index, columns=data_df.columns\n",
    ")\n",
    "\n",
    "#  split as in traing of the model\n",
    "train_df, test_df = train_test_split(data_df, test_size=0.33, random_state=42, stratify=data_df.category)\n",
    "test_df, valid_df = train_test_split(test_df, test_size=0.67, random_state=42, stratify=test_df.category)\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = train_df.columns[:-1]\n",
    "\n",
    "X_train = train_df[markers].values\n",
    "X_test = test_df[markers].values\n",
    "X_valid = valid_df[markers].values\n",
    "\n",
    "y_train = train_df['category'].values.astype(np.int)\n",
    "y_test = test_df['category'].values.astype(np.int)\n",
    "y_valid = valid_df['category'].values.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data_df.category)\n",
    "CellTyper.celltype_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pretrained model\n",
    "is actually done under the hood by a child implementation of `depiction.models.uri.HTTPModel`. \n",
    "Change `filename`, `cache_dir` (with fixed subdir `models/`) and/or `origin` to load/download a different model.\n",
    "Or have a look at other uri models, e.g `FileSystemModel` or `RESTAPIModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained classifier\n",
    "classifier = CellTyper(filename='celltype_model.h5')\n",
    "# classifier.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = classifier.model.layers[0].get_weights()[0]\n",
    "sns.heatmap(pd.DataFrame(\n",
    "    weights,\n",
    "    index=markers,\n",
    "#     columns=CellTyper.celltype_names.values()\n",
    ").T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare qualitatively to __B__ and **C** (thought the image is not depicting this exact dataset)\n",
    "![manual_gated](https://science.sciencemag.org/content/sci/332/6030/687/F2.large.jpg?width=800&height=600&carousel=1)\n",
    "from https://science.sciencemag.org/content/332/6030/687/tab-figures-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper/widget functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_from_class(label):\n",
    "    id_sample_to_explain = test_df.reset_index().query('category==@label').sample(n=1).index[0]\n",
    "    print('Interpreting sample with index {} in test_df'.format(id_sample_to_explain))\n",
    "    return id_sample_to_explain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_logits(id_sample_to_explain):\n",
    "    sample = X_test[id_sample_to_explain]\n",
    "    logits = pd.DataFrame(classifier.predict([[sample]]), columns=CellTyper.celltype_names.values()).T\n",
    "    sns.heatmap(logits)\n",
    "\n",
    "\n",
    "def visualize(id_sample_to_explain, layer):\n",
    "    sample = X_test[id_sample_to_explain]\n",
    "    if layer is None:\n",
    "        visualize_logits(id_sample_to_explain)\n",
    "        return\n",
    "    elif layer==0:\n",
    "        # output of last \"layer\" is the sample\n",
    "        layer_output = sample.transpose()\n",
    "    else:\n",
    "        # for vizualization of output of a layer we access the model\n",
    "        activation_model = keras.models.Model(\n",
    "            inputs=classifier.model.input,\n",
    "            outputs=classifier.model.layers[layer-1].output\n",
    "        )\n",
    "        layer_output = activation_model.predict([[sample]])[0]\n",
    "    \n",
    "    weights = classifier.model.layers[layer].get_weights()[0]\n",
    "    weighted_output = (weights.transpose() * layer_output)\n",
    "    sns.heatmap(weighted_output)\n",
    "\n",
    "\n",
    "def visualize_random_from_class(label, layer):\n",
    "    visualize(random_from_class(label), layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(\n",
    "    visualize_random_from_class,\n",
    "    label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "    layer=dict(\n",
    "        **{layer.name: i for i, layer in enumerate(classifier.model.layers)}, logits=None\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_logits(4368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability methods\n",
    "starting with \"local\" methods, explaining a given sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LIME tabular interpreter\n",
    "lime_params = {\n",
    "    'training_data': X_train,\n",
    "    'training_labels': y_train,\n",
    "    'feature_names': markers,\n",
    "    'verbose': True,\n",
    "    'class_names': classifier.celltype_names.values(),\n",
    "    'discretize_continuous': False,\n",
    "    'sample_around_instance': True\n",
    "}\n",
    "\n",
    "lime = UWasher(\"lime\", classifier, **lime_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_params = {\n",
    "    'feature_names': markers,\n",
    "    'class_names': classifier.celltype_names.values(),\n",
    "    'categorical_names': {}\n",
    "}\n",
    "fit_params = {  # depiction fits the anchor (tabular) on contruction.\n",
    "    'train_data': X_train,\n",
    "    'train_labels': y_train,\n",
    "    'validation_data': X_valid,\n",
    "    'validation_labels': y_valid\n",
    "}\n",
    "\n",
    "anchors = UWasher('anchors', classifier, **fit_params, **anchors_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_params = {\n",
    "    # setting some parameters\n",
    "    'shape': (1, 13), # with batch size\n",
    "    'target_proba': 1.0,\n",
    "    'tol': 0.1, # tolerance for counterfactuals\n",
    "    'max_iter': 10,\n",
    "    'lam_init': 1e-1,\n",
    "    'max_lam_steps': 10,\n",
    "    'learning_rate_init': 0.1,\n",
    "    'feature_range': (X_train.min(),X_train.max())\n",
    "}\n",
    "\n",
    "counterfactual = Counterfactual(\n",
    "    classifier,\n",
    "    target_class='other',  # any other class\n",
    "    **counterfactual_params,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper/widget functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_with_lime(id_sample_to_explain):\n",
    "    \"\"\"Explain the chosen instance wrt the chosen label.\"\"\"\n",
    "    lime.interpret(X_test[id_sample_to_explain], explanation_configs={'top_labels': 1})\n",
    "\n",
    "\n",
    "def anchor_callback(sample, **kwargs):\n",
    "    \"\"\"Explain the chosen instance wrt the chosen labels.\"\"\"\n",
    "    return np.argmax(classifier.predict(sample,**kwargs), axis=1)\n",
    "\n",
    "\n",
    "def interpret_with_anchor(id_sample_to_explain):\n",
    "    anchors.interpret(X_test[id_sample_to_explain], explanation_configs={},callback=anchor_callback)\n",
    "\n",
    "\n",
    "def interpret_with_counterfactual(id_sample_to_explain):\n",
    "    \"\"\"Explain the chosen instance wrt the chosen label.\"\"\"\n",
    "    explanation = counterfactual.interpret(np.expand_dims(X_train[0], axis=0))  # with batch size\n",
    "    predicted_class = explanation['cf']['class']\n",
    "    probability = explanation['cf']['proba'][0][predicted_class]\n",
    "    print(f'Counterfactual prediction: {predicted_class} with probability {probability}')\n",
    "    print(explanation['cf']['X'])\n",
    "\n",
    "\n",
    "def interpret_random_from_class(label, interpreter):\n",
    "    id_sample_to_explain = random_from_class(label)\n",
    "    if interpreter == 'lime':\n",
    "        interpret_with_lime(id_sample_to_explain)\n",
    "    elif interpreter == 'anchor':\n",
    "        interpret_with_anchor(id_sample_to_explain)\n",
    "    elif interpreter == 'counterfactual':\n",
    "        interpret_with_counterfactual(id_sample_to_explain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(interpret_random_from_class, label=[(v, k) for k, v in classifier.celltype_names.items()],\n",
    "         interpreter=['lime', 'anchor', 'counterfactual']\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_with_anchor(4368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global interpretation with rule-based models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2ID = {CellTyper.celltype_names[i]: i for i in CellTyper.celltype_names.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_TO_EXPLAIN = 'Mature CD4+ T'\n",
    "LABEL_ID = LABEL2ID[LABEL_TO_EXPLAIN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the task to use this method\n",
    "model = BinarizedClassifier(classifier, data_type=DataType.TABULAR, label_index=LABEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Hoc explanation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('brcg', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_linear', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_logistic', X=X_train, model=model)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ante-Hoc explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = y_train == LABEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('brcg', X=X_train, y=y_train_binary)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_linear', X=X_train, y=y_train_binary)\n",
    "interpreter.interpret()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLRM - Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = RuleAIX360('glrm_logistic', X=X_train, y=y_train_binary)\n",
    "interpreter.interpret()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
