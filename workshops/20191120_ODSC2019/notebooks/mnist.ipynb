{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting predictions on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import warnings; warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf; tf.logging.set_verbosity(tf.logging.ERROR)  # suppress deprecation messages\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from depiction.core import Task, DataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "_ = plt.gray()\n",
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general variables\n",
    "# NOTE: get a valid cache (but only once!)\n",
    "CACHE_DIR = None\n",
    "if CACHE_DIR is None:\n",
    "    CACHE_DIR = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# general utils\n",
    "def transform(x):\n",
    "    \"\"\"\n",
    "    Move to -0.5, 0.5 range and add channel dimension.\n",
    "    \n",
    "    Args:\n",
    "        x (np.ndarray): a 2D-array representing an image.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: a 3D-array representing the transformed image.\n",
    "    \"\"\"\n",
    "    return np.expand_dims(x.astype('float32') / 255 - 0.5, axis=-1)\n",
    "\n",
    "\n",
    "def transform_sample(x):\n",
    "    \"\"\"\n",
    "    Add dimension representing the batch size.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): a 3D-array represnting an image.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: a 4D-array representing a batch with a\n",
    "            single image.\n",
    "    \"\"\"\n",
    "    return np.expand_dims(transform(x), axis=0)\n",
    "\n",
    "\n",
    "def inverse_transform(x):\n",
    "    \"\"\"\n",
    "    Apply an inverse transform on a batch with a single image.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): a 4D-array representing a batch with a\n",
    "            single image.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: a 3D-array represnting an image.\n",
    "    \"\"\"\n",
    "    return (x.squeeze() + 0.5) * 255\n",
    "\n",
    "\n",
    "def show_image(x, title=None):\n",
    "    \"\"\"\n",
    "    Show an image.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): a 4D-array representing a batch with a\n",
    "            single image.\n",
    "        title (str): optional title.\n",
    "    \"\"\"\n",
    "    axes_image = plt.imshow(x.squeeze())\n",
    "    axes_image.axes.set_xticks([], [])\n",
    "    axes_image.axes.set_yticks([], [])\n",
    "    if title is not None:\n",
    "        axes_image.axes.set_title(title)\n",
    "    return axes_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a model to intepret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.models.keras import KerasModel\n",
    "from tensorflow.keras.models import load_model\n",
    "from depiction.models.base.utils import get_model_file\n",
    "\n",
    "depiction_model = KerasModel(\n",
    "    load_model(\n",
    "        get_model_file(\n",
    "            filename='mninst_cnn.h5',\n",
    "            origin='https://ibm.box.com/shared/static/v3070m2y62qw4mpwl04pee75n0zg681g.h5',\n",
    "            cache_dir=CACHE_DIR\n",
    "        )\n",
    "    ),\n",
    "    task=Task.CLASSIFICATION, data_type=DataType.IMAGE\n",
    ")\n",
    "depiction_model._model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "print('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape, 'y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index = 42\n",
    "example = transform_sample(x_test[index])\n",
    "label = y_test[index]\n",
    "show_image(\n",
    "    example,\n",
    "    title=(\n",
    "        f'True={label} '\n",
    "        f'Predicted={np.argmax(depiction_model.predict(example))}'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is our model doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "score = depiction_model._model.evaluate(\n",
    "    transform(x_test), to_categorical(y_test), verbose=0\n",
    ")\n",
    "print(f'Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.interpreters.u_wash import UWasher\n",
    "\n",
    "lime_interpreter = UWasher('lime', depiction_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_interpreter.interpret(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utilities\n",
    "def show_cem_explanation(explanation, mode):\n",
    "    \"\"\"\n",
    "    Show a CEM explanation for images.\n",
    "\n",
    "    Args:\n",
    "        explanation (dict): CEM explanation.\n",
    "        mode (str): CEM mode, PP or PN.\n",
    "    \"\"\"\n",
    "    prediction_key = f'{mode}_pred'\n",
    "    if prediction_key in explanation:\n",
    "        print(f'{mode} prediction: {explanation[prediction_key]}')\n",
    "        show_image(\n",
    "            explanation[mode],\n",
    "            title=(f'{mode} explanation for example provided.')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# setting some parameters\n",
    "shape = example.shape\n",
    "kappa = 0.  # minimum difference needed between the prediction probability for the perturbed instance on the\n",
    "# class predicted by the original instance and the max probability on the other classes\n",
    "# in order for the first loss term to be minimized\n",
    "beta = .1  # weight of the L1 loss term\n",
    "gamma = 100  # weight of the optional auto-encoder loss term\n",
    "c_init = 1.  # initial weight c of the loss term encouraging predictions for the perturbed instance compared to the original instance to be explained\n",
    "c_steps = 10  # updates for c\n",
    "max_iterations = 10  # iterations per value of c\n",
    "feature_range = (x_train.min(), x_train.max())  # feature range for the perturbed instance\n",
    "clip = (-1000., 1000.)  # gradient clipping\n",
    "lr = 1e-2  # initial learning rate\n",
    "no_info_val = -1.  # picking value close to background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# NOTE: CEM supports the usage of an autoencoder to impose a variation on a latent manifold\n",
    "ae = load_model(\n",
    "    get_model_file(\n",
    "        filename='mninst_ae.h5',\n",
    "        origin=\n",
    "        'https://ibm.box.com/shared/static/psogbwnx1cz0s8w6z2fdswj25yd7icpi.h5',  # noqa\n",
    "        cache_dir=CACHE_DIR\n",
    "    )\n",
    ")\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from depiction.interpreters.alibi import CEM\n",
    "\n",
    "cem_pn_interpreter = CEM(\n",
    "    depiction_model,\n",
    "    'PN',  # pertinent negative\n",
    "    shape,\n",
    "    kappa=kappa,\n",
    "    beta=beta,\n",
    "    feature_range=feature_range,\n",
    "    gamma=gamma,\n",
    "    ae_model=ae,\n",
    "    max_iterations=max_iterations,\n",
    "    c_init=c_init,\n",
    "    c_steps=c_steps,\n",
    "    learning_rate_init=lr,\n",
    "    clip=clip,\n",
    "    no_info_val=no_info_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cem_pn_explanation = cem_pn_interpreter.interpret(example)\n",
    "show_cem_explanation(cem_pn_explanation, 'PN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from depiction.interpreters.alibi import CEM\n",
    "\n",
    "cem_pp_interpreter = CEM(\n",
    "    depiction_model,\n",
    "    'PP',  # pertinent positive\n",
    "    shape,\n",
    "    kappa=kappa,\n",
    "    beta=beta,\n",
    "    feature_range=feature_range,\n",
    "    gamma=gamma,\n",
    "    ae_model=ae,\n",
    "    max_iterations=max_iterations,\n",
    "    c_init=c_init,\n",
    "    c_steps=c_steps,\n",
    "    learning_rate_init=lr,\n",
    "    clip=clip,\n",
    "    no_info_val=no_info_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "cem_pp_explanation = cem_pp_interpreter.interpret(example)\n",
    "show_cem_explanation(cem_pp_explanation, 'PP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counterfactual_explanation(explanation):\n",
    "    \"\"\"\n",
    "    Show a counterfactual explanation for images.\n",
    "\n",
    "    Args:\n",
    "        explanation (dict): counterfactual explanation.\n",
    "    \"\"\"\n",
    "    predicted_class = explanation['cf']['class']\n",
    "    probability = explanation['cf']['proba'][0][predicted_class]\n",
    "    print(f'Counterfactual prediction: {predicted_class} with probability {probability}')\n",
    "    show_image(explanation['cf']['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# setting some parameters\n",
    "shape = example.shape\n",
    "target_proba = 1.0\n",
    "tol = 0.1 # tolerance for counterfactuals\n",
    "max_iter = 10\n",
    "lam_init = 1e-1\n",
    "max_lam_steps = 10\n",
    "learning_rate_init = 0.1\n",
    "feature_range = (x_train.min(),x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from depiction.interpreters.alibi import Counterfactual\n",
    "\n",
    "counterfactual_interpreter = Counterfactual(\n",
    "    depiction_model,\n",
    "    shape=shape, target_proba=target_proba, tol=tol,\n",
    "    target_class='other',  # any other class\n",
    "    max_iter=max_iter, lam_init=lam_init,\n",
    "    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n",
    "    feature_range=feature_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "counterfactual_explanation = counterfactual_interpreter.interpret(example)\n",
    "show_counterfactual_explanation(counterfactual_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from depiction.interpreters.alibi import Counterfactual\n",
    "\n",
    "counterfactual_interpreter = Counterfactual(\n",
    "    depiction_model,\n",
    "    shape=shape, target_proba=target_proba, tol=tol,\n",
    "    target_class=1,  # focusing on a specific class \n",
    "    max_iter=max_iter, lam_init=lam_init,\n",
    "    max_lam_steps=max_lam_steps, learning_rate_init=learning_rate_init,\n",
    "    feature_range=feature_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explanation = counterfactual_interpreter.interpret(example)\n",
    "show_counterfactual_explanation(counterfactual_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
