{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting predictions on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import warnings; warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import tensorflow as tf; tf.logging.set_verbosity(tf.logging.ERROR)  # suppress deprecation messages\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import keras_applications\n",
    "from tensorflow import keras\n",
    "from ipywidgets import interact\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from depiction.core import DataType, Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general utils\n",
    "def image_preprocessing(image_path, preprocess_input, target_size):\n",
    "    \"\"\"\n",
    "    Read and preprocess an image from disk.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): path to the image.\n",
    "        preprocess_input (funciton): a preprocessing function.\n",
    "        target_size (tuple): image target size.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: the preprocessed image.\n",
    "    \"\"\"\n",
    "    image = keras.preprocessing.image.load_img(\n",
    "        image_path, target_size=target_size\n",
    "    )\n",
    "    x = keras.preprocessing.image.img_to_array(image)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    return preprocess_input(x)\n",
    "\n",
    "\n",
    "def get_imagenet_labels():\n",
    "    \"\"\"\n",
    "    Get ImamgeNet labels.\n",
    "\n",
    "    Returns:\n",
    "        list: list of labels.\n",
    "    \"\"\"\n",
    "    labels_filepath = keras.utils.get_file(\n",
    "        'imagenet_class_index.json',\n",
    "        keras_applications.imagenet_utils.CLASS_INDEX_PATH\n",
    "    )\n",
    "    with open(labels_filepath) as fp:\n",
    "        labels_json = json.load(fp)\n",
    "    labels = [None] * len(labels_json)\n",
    "    for index, (_, label) in labels_json.items():\n",
    "        labels[int(index)] = label\n",
    "    return labels\n",
    "\n",
    "\n",
    "def show_image(x, title=None):\n",
    "    \"\"\"\n",
    "    Show an image.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray): a 4D-array representing a batch with a\n",
    "            single image.\n",
    "        title (str): optional title.\n",
    "    \"\"\"\n",
    "    axes_image = plt.imshow(x.squeeze())\n",
    "    axes_image.axes.set_xticks([], [])\n",
    "    axes_image.axes.set_yticks([], [])\n",
    "    if title is not None:\n",
    "        axes_image.axes.set_title(title)\n",
    "    return axes_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate a model to intepret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.models.keras import KerasApplicationModel\n",
    "# instantiate the model\n",
    "model = KerasApplicationModel(\n",
    "    keras.applications.MobileNetV2(), Task.CLASSIFICATION, DataType.IMAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "labels = get_imagenet_labels()\n",
    "examples = {}\n",
    "for filename, url in [\n",
    "    ('elephant.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/f/f9/Zoorashia_elephant.jpg/120px-Zoorashia_elephant.jpg'),\n",
    "    ('dog.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Welsh_Springer_Spaniel.jpg/400px-Welsh_Springer_Spaniel.jpg'),\n",
    "    ('cat.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Six_weeks_old_cat_%28aka%29.jpg/400px-Six_weeks_old_cat_%28aka%29.jpg'),\n",
    "    ('cat-and-dog.jpg.', 'https://upload.wikimedia.org/wikipedia/commons/9/97/Greyhound_and_cat.jpg'),\n",
    "    ('plush.jpg', 'https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Plush_bunny_with_headphones.jpg/320px-Plush_bunny_with_headphones.jpg')\n",
    "]:\n",
    "    filepath = keras.utils.get_file(filename, url)\n",
    "    examples[filename.split('.')[0]] = image_preprocessing(\n",
    "        filepath,\n",
    "        keras.applications.mobilenet_v2.preprocess_input,\n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "interact(lambda key: show_image(examples[key], title=f'{key}'), key=examples.keys());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an example\n",
    "image = examples['elephant']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.interpreters.u_wash import UWasher\n",
    "\n",
    "interpreter = UWasher('lime', model, class_names=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explanation = interpreter.interpret(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depiction.interpreters.u_wash import UWasher\n",
    "\n",
    "interpreter = UWasher('anchors', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = interpreter.interpret(image)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
